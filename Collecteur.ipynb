{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Collecteur.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFpKPmeOUPS5"
      },
      "source": [
        "# Scrapper de sites\n",
        "\n",
        "> Récupère le contenu de chacun des URL classé par typologie (variable ndf dans le code), chargé depuis le fichier Sites.json issu du dossier ressources.\n",
        "\n",
        "> Stocke le résultat dans ndf qui conditionne la variable \"fichier de sortie\" : un fichier par catégorie de site. Celle-ci peut être adaptée pour pointer sur une zone correcte de votre drive dans la zone \"Personnalisation\" dénotée ci-dessous. Les données des sites collectés sont stockées au format pickle dans le dossier /OUT/ContenusSites classé par typologie selon Sites.json.\n",
        "\n",
        "> La variable de sortie est de type dictionnaire pour conserver les url sources (flexibilité pour pouvoir corriger). Cf. commentaires infra. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0A5eMDAyoOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970b145f-345d-447f-c1fb-8540ef0e44aa"
      },
      "source": [
        "# Il faut initialiser le dossier à partir de GitHub\n",
        "# cette action est à faire une seule fois lors de la première utilisation\n",
        "!git clone https://github.com/Patent2net/LexiComWeb.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LexiComWeb'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 38 (delta 6), reused 37 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (38/38), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra410KOWyoyR"
      },
      "source": [
        "stockageEntree = \"/content/LexiComWeb/\"\n",
        "stockageSortie = \"/content/LexiComWeb/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG9t6FFyV3f6"
      },
      "source": [
        "import os\n",
        "os.chdir(\"LexiComWeb/RESSOURCES\")\n",
        "from outils import isPartner, text_from_html, myRequest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txv0Pk7P_xbw"
      },
      "source": [
        "\n",
        "---\n",
        "# Personnalisation (Option)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rntapC_RCnd"
      },
      "source": [
        "> Ces cellules permettent de réaliser les traitements à partir de son propre espace de stockage. A n'exécuter que dans ce cas en adaptant les dossiers d'entrée et sortie. NE PAS EXECUTER SAUF A PERSONNALISER LES TRAITEMENTS\n",
        "\n",
        "Si vous voulez exécuter ce notebook sur vos propres données il faut reconstituer l'ensemble des dossiers nécessaires sur votre drive dans un dossier OUT situé à la racine (cf. les variables *stockageEntree* et *stockageSortie*), ces cellules vous permettent de configurer cet outil pour travailler sur vos données et non celles issues du git (accessibles sur un dossier virtuel via le menu *Fichiers* à gauche).."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr3_QQJq_veT",
        "outputId": "e947e98e-20d2-4e43-b322-6a7a79f7e9ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ozLFiEG_w5H"
      },
      "source": [
        "# Récupérer les sorties sur son drive (créer un dossier \"OUT\")\n",
        "stockageSortie = \"/content/drive/MyDrive/OUT\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpnXg8eWHorz"
      },
      "source": [
        "# Récupérer les entrées sur son drive\n",
        "stockageEntree = \"/content/drive/MyDrive/OUT\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbKLKuPg_0jY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement des librairies"
      ],
      "metadata": {
        "id": "13SgmNdvFbyU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvC9l2YvRmP9"
      },
      "source": [
        "import requests, re, pickle, urllib\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement des URL à traiter \n",
        "> les urls à collecter sont classés dans une typologie de sites "
      ],
      "metadata": {
        "id": "j-NJpNgbUnbX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYD-cWsJzFMn"
      },
      "source": [
        "import json\n",
        "with open(stockageEntree + '/RESSOURCES/Sites.json', 'r', encoding='utf-8') as f:\n",
        "    CatSites = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb = 0\n",
        "for truc in CatSites .keys():\n",
        " nb += len( CatSites [truc][0])\n",
        " print (truc, nb, CatSites [truc] [0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv4fU9X18sYi",
        "outputId": "4cf39b89-70ab-40d1-ad55-c6263df17e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gouv 6 ['http://ofb.gouv.fr', 'http://agriculture.gouv.fr', 'http://ecologique-solidaire.gouv.fr', 'http://culture.gouv.fr', 'http://developpement-durable.gouv.fr', 'http://diplomatie.gouv.fr']\n",
            "parcs 16 ['http://www.vanoise-parcnational.fr/fr', 'http://www.pyrenees-parcnational.fr/fr', 'http://www.cevennes-parcnational.fr/fr', 'http://www.ecrins-parcnational.fr/', 'http://www.mercantour-parcnational.fr/fr', 'http://www.guadeloupe-parcnational.fr/fr', 'http://www.parc-amazonien-guyane.fr/fr', 'http://www.reunion-parcnational.fr/fr', 'http://www.calanques-parcnational.fr/fr', 'http://www.forets-parcnational.fr/fr']\n",
            "orga 37 ['http://ademe.fr', 'http://ffcam.fr', 'http://parcsetjardins.fr', 'http://ffrandonnee.fr', 'http://fondation-patrimoine.org', 'http://iucn.org', 'http://onf.fr', 'http://ffem.fr', 'http://sanctuaire-pelagos.org', 'http://fondationbiodiversite.fr', 'http://eaurmc.fr', 'http://sfepm.org', 'http://ffe.com', 'http://atout-france.fr', 'http://naturefrance.fr', 'http://fondationcarmignac.com', 'http://guillestrois.com', 'http://foretpriveefrancaise.com', 'http://natura2000.fr', 'http://grandsitedefrance.com', 'http://pifh.fr']\n",
            "oTourism 61 ['http://mpmtourisme.com', 'http://visitvar.fr', 'http://toulontourisme.com', 'http://bandoltourisme.fr', 'http://tourismepaca.fr', 'http://bormeslesmimosas.com', 'http://lepradet-tourisme.fr', 'http://paysdesecrins.com', 'http://paysdefayence.com', 'https://www.la-provence-verte.net/index.php', 'http://provence-alpes-cotedazur.com', 'http://gassin.eu', 'http://ramatuelle-tourisme.com', 'http://sanary-tourisme.com', 'http://plongee-hyeres.com', 'http://iledulevant.com.fr', 'http://gap-tourisme.fr', 'http://isere-tourisme.com', 'http://hyeres-tourisme.com', 'http://savoie-mont-blanc.com', 'http://www.tourismeprovencemediterranee.com/', 'http://tourisme-ouestvar.com', 'http://saintcyrsurmer.com', 'http://sainte-maxime.com']\n",
            "Services 173 ['http://grand-tour-ecrins.fr', 'http://casinohyeres.com', 'http://aquafamily.fr', 'http://ignrando.fr', 'https://www.kiddyparc.com/', 'http://artdanh.com', 'http://balade-en-mer-83.fr', 'http://tlv-tvm.com', 'http://aquavillageparc.com', 'http://thalassa.com', 'http://squashclub4.fr', 'http://kitecenter83.fr', 'http://aphroditespa.fr', 'http://spacoupole-hyeres.com', 'http://toulon-hyeres.aeroport.fr', 'http://spinout.fr', 'http://amotos.fr', 'http://rosalieandco.com', 'http://kraken-sports-nautiques.com', 'http://clubkayaklepradet.fr', 'http://plongee-var.fr', 'http://fracpaca.org', 'http://aquabulles-plongee.fr', 'http://reseaumistral.com', 'http://lacledutemps.fr', 'http://cinemasolbia.com', 'http://votrechauffeurprive.fr', 'http://chauffeurdesilesdor.com', 'http://group-indigo.com', 'http://ada.fr', 'http://art-et-vin.net', 'http://activiteez.com', 'http://baladesdecharlotte.fr', 'http://kubilai-khan-constellations.com', 'http://galerie-marieposcia.fr', 'http://lesbonnespuces.com', 'http://stephanemifsud.fr', 'http://ileo-porquerolles.fr', 'http://porquerolles-plongee.com', 'http://hyeres-plongee.com', 'http://cyana-plongee.com', 'http://plongeeo.com', 'http://lafeeplongee.fr', 'http://gite-de-plongee-du-gapeau.com', 'http://randomarine.com', 'http://vedettesilesdor.fr', 'http://labelleplace.fr', 'http://anas.asso.fr', 'http://sellerie-nautique-var-83.com', 'http://galerie-massillon.fr', 'http://jessicadrouin.com', 'http://serre-chevalier.com', 'http://bourgdoisans.com', 'http://chaillol.fr', 'http://orcieres.com', 'http://venosc.com', 'http://les2alpes.com', 'http://sylvieadaoust.com', 'http://metiersdart-paca.fr', 'http://lespritvitrail.com', 'http://elisabethserregalerie.com', 'http://bateliersdelacotedazur.com', 'http://weekend-provence.fr', 'http://francevelotourisme.com', 'http://funboardcenter.com', 'http://bouisse-matteri.fr', 'http://mauvanne.com', 'http://hexavoile.com', 'http://apgiens.com', 'http://brigantin.fr', 'http://catamaran-var.com', 'http://riding-watt.com', 'http://observation-cetaces.fr', 'http://verticalhorizon.fr', 'http://swellpassion-surfshop.fr', 'http://kiteplus-hyeres.com', 'http://mfkite.com', 'http://plancheexpresslocation.com', 'http://ideole.fr', 'http://kitesurf-hyeres.com', 'http://kitesurfhyeres.com', 'http://kite-hyeres.fr', 'http://secretrip.pro', 'http://sea-ride.eu', 'http://sensation-sailing.fr', 'http://kifkite.fr', 'http://hobie-shop.com', 'http://welcomesurfhyeres.com', 'http://iceberg-jet.com', 'http://vacanciel.com', 'http://bowlingprovence.com', 'http://www.gr2013.fr', 'http://apidae-tourisme.com', 'http://standuppaddlestation.over-blog.com', 'http://golfe-saint-tropez-information.com', 'http://la-draille-hyeroise.blogspot.fr', 'http://moulinesquirol-oliveraie.com', 'http://wallgreen.com', 'http://gravityspace83.com', 'http://pierreetvacances.com', 'http://anae.asso.fr', 'http://golf-valgarde.com', 'http://bateauxverts.com', 'http://lesbateliersdelarade.com', 'http://latitudeverte.fr', 'http://atlantide1.com', 'http://bateauxsaintraphael.com', 'http://croixdusud5.com', 'http://aventurecheval.fr', 'http://mesclances.com', 'http://laruchequiditoui.fr', 'http://chateau-castille.fr']\n",
            "Hebergements 298 ['http://heliotel.net', 'http://porquerolles-location.fr', 'http://vacancealamer.com', 'http://campingmauvallon.fr', 'http://lesilespaulricard.com', 'http://domainedelanavicelle.com', 'http://camping-hermitage.com', 'http://campingloupantai.com', 'http://pradet-vacances.com', 'http://campeole.com', 'http://labastidedespins.fr', 'http://campingdupindegalle.com', 'http://villa-antoine-lepradet.com', 'http://campingartaudois.com', 'http://hotel-escapade.com', 'http://location-var-vacances.com', 'http://azuretpalmiers.fr', 'http://leyoukali.fr', 'http://augrandsud.com', 'http://chateau-la-clapiere.com', 'http://lhc-vacances.fr', 'http://abritel.fr', 'http://labastide-decharlotte.fr', 'http://lacigalevaroise.com', 'http://fouques-bio.com', 'http://residence-lagabiniere.com', 'http://instant-lacapte.com', 'http://villanoailles-hyeres.com', 'http://provencalhotel.com', 'http://gites-de-france-var.fr', 'http://clevacances.com', 'http://villa-carmignac.com', 'http://mercure.com', 'http://ibis.com', 'http://larchedeporquerolles.com', 'http://sainteanne.com', 'http://accorhotels.com', 'http://auberge-glycines.com', 'http://hotel-les-medes.fr', 'http://labrisemarine.net', 'http://bestwestern.fr', 'http://hotel-almanarreplage.com', 'http://domainedelamer.com', 'http://parc.fr', 'http://hotel-orangers.fr', 'http://langoustier.com', 'http://lapotiniere83.com', 'http://lido-beach.com', 'http://logishotels.com', 'http://hotelcasinohyeres.com', 'http://hotel-bb.com', 'http://hotel-du-soleil.fr', 'http://oustaou.com', 'http://hotelcalypso.fr', 'http://hotel-lemanoirportcros.com', 'http://lelodgedesilesdor.com', 'http://lareinejane.fr', 'http://hotelgaetan.com', 'http://auporquerollais.com', 'http://labastide-hyeres.com', 'http://hotelmed.info', 'http://hotel-bor.com', 'http://lerocherdusecret.com', 'http://galaxy-reservation.fr', 'http://lamagnanerie.eu', 'http://ingenie.fr', 'http://porquerolles-immobilier.fr', 'http://mesomax.fr', 'http://alycastre.com', 'http://tiloulocation.com', 'http://booking.com', 'http://regard-sur-mer.com', 'http://s-lux.net', 'http://homelidays.com', 'http://ledongiovanni.com', 'http://camping-beauveze.com', 'http://hotel-brise-marine.com', 'http://gite-rural-hyeres.com', 'http://valdazur.com', 'http://hotelrichiardi.com', 'http://location-vacances-porquerolles.com', 'http://gites-de-france.com', 'http://residenceatlantis.fr', 'http://lesurplage.com', 'http://lapinedebleue.com', 'http://lapinede-iledulevant.com', 'http://les-sables-dor.fr', 'http://villaeglantine.com', 'http://lesilesdordulevant.fr', 'http://villamariejeanne.fr', 'http://les-stoechades.com', 'http://varlocationsvacances.com', 'http://labaratonne.com', 'http://naturiste.com', 'http://gitedupagoulin.fr', 'http://aufrene.com', 'http://lepavillondespivoines-chambredhotes.com', 'http://camping-les-joseph.fr', 'http://ceinturon3.fr', 'http://international-giens.com', 'http://lespeuplierscamping.fr', 'http://campingportpothuau.com', 'http://camping-giens.com', 'http://campingclairdelune.fr', 'http://camping-olbia.com', 'http://parc-plage.com', 'http://camping-les-palmiers.fr', 'http://campingcapricorne.com', 'http://camping-vert-gapeau.com', 'http://campinglabergerieplage.com', 'http://camping-latourfondue.com', 'http://camping-lemed.fr', 'http://camping-iles-d-or.com', 'http://lespinsmaritimes.fr', 'http://capfun.com', 'http://mareesole.com', 'http://sigalous.com', 'http://location-meublee-hyeres.com', 'http://lavillaclairfelie.wordpress.com', 'http://chezlessoeursa-carqueiranne.fr', 'http://chambres-hotes-giraglia.com', 'http://porquerolles-chez-yvette.com', 'http://residencelesmandariniers.com', 'http://azureor-location-vacances.com', 'http://campingsaintpierredeshorts.com']\n",
            "restauration 337 ['http://legambaro.com', 'http://lafourmidulevant.com', 'http://restaurantlachanterelle.fr', 'http://lacheesecantine.fr', 'http://restaurant-sushima.com', 'http://pizza-porquerolles.fr', 'http://ilpescatore-porquerolles.fr', 'http://vice-versa-restaurant-hyeres.com', 'http://ilcasale.fr', 'http://resto-plage-laventure.fr', 'http://faymburger.com', 'http://maisondessaveurs.fr', 'http://pizzatomic.fr', 'http://la-saga.fr', 'http://lepubcarqueiranne.fr', 'http://le-cabrol.com', 'http://lacaseasausse.fr', 'http://e-sushi83.com', 'http://faym-food.com', 'http://lesbarbouzes.com', 'http://lemediterranee-hyeres.fr', 'http://lemaraisplage.fr', 'http://lepeople.fr', 'http://pizzalevenezia.fr', 'http://restaurantlacolombe.com', 'http://restaurant-la-jeannette.com', 'http://lataverne-royale.com', 'http://restaurantlafregate.fr', 'http://mojitocafe.fr', 'http://pizza-lacapte.fr', 'http://restaurantlepoissonrouge.fr', 'http://tonyburger.net', 'http://restaurantlesolarium.fr', 'http://sfthai.fr', 'http://restaurant-pizzeria-hyeres.com', 'http://ansedeportcros.com', 'http://brasserie-des-iles.com', 'http://lequaihyeres.com', 'http://planb-hyeres.com']\n",
            "locations 371 ['http://lindien.fr', 'http://velo-porquerolles.com', 'http://le-pirate-porquerolles.com', 'http://loca-bikes.com', 'http://velosaporquerolles.com', 'http://porquerolles-a-velo.fr', 'http://iych.fr', 'http://la-becane-porquerolles.fr', 'http://porquerollesavelo.com', 'http://bateau-porquerolles.fr', 'http://govirtuo.com', 'http://innovan-lair.fr', 'http://taxis-hyeres.com', 'http://bateaux-taxi.com', 'http://budget.fr', 'http://esterel-cotedazur.com', 'http://ecrinsdelabadine.com', 'http://lindien-location-velo.fr', 'http://flyboard-hyeres.com', 'http://ilesdorevasion.com', 'http://accostagelocation.fr', 'http://rosalies-hyeres.com', 'http://location-de-catamaran.com', 'http://mistral-marine.com', 'http://porquerolles.pro', 'http://reverloc.fr', 'http://levasionbleue.com', 'http://voileetvent.com', 'http://wanako-location.fr', 'http://fil-etrave.com', 'http://audemar.com', 'http://aquaboat83.com', 'http://porquerolles-yachting.com', 'http://plaisance-location-bateau-hyeres.com']\n",
            "mairies 379 ['http://la-seyne.fr', 'http://le-pradet.fr', 'http://isere.fr', 'http://hyeres.fr', 'http://ville-lagarde.fr', 'http://toulon.fr', 'http://carqueiranne.fr', 'http://villedelacrau.fr']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (nb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT929_z19mu1",
        "outputId": "15964aed-0975-455f-96b1-82ab73fcec54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zxsE3AeBrCd"
      },
      "source": [
        "# Première boucle pour lever les problèmes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxW6KJySZijW"
      },
      "source": [
        "import urllib3\n",
        "urllib3.disable_warnings() # pourquoi les certificats SSL ne passent pas aujourd'hui ? 30/11 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhM4fmUohayD"
      },
      "source": [
        "> La dynamique du web fait que certains sites peuvent ne pas être accessibles, ne pas répondre à un instant t, ou faire planter le collecteur. Ce qui suit teste chaque URL et construit la variable BadUrl avec les urls en erreur.\n",
        "\n",
        "changements 01/22: la fonction myRequest implémente :\n",
        "1. la gestion du timeout (3 secondes), le collecteur ne devrait plus planter\n",
        "2. de réssayer 3 fois en cas d'erreurs particulières (429, 502, 501)\n",
        "3. ✋ ne cherche pas à vérifier le certificat SSL suite aux erreurs rencontrées ces jours ci ❗ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZUYVvJjWKIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1f5358-e86b-4f58-c56f-0fbab2a8fa02"
      },
      "source": [
        "BadUrl = dict()\n",
        "Done = []\n",
        "for ndc in CatSites.keys():\n",
        "  if ndc not in BadUrl.keys() and ndc not in Done:\n",
        "    BadUrl[ndc] = []\n",
        "    print(ndc)\n",
        "    for url in CatSites[ndc][0]: \n",
        "      try:\n",
        "        webpage = myRequest(url)\n",
        "      except:\n",
        "        print(\"bad\", url)\n",
        "        BadUrl[ndc].append(url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gouv\n",
            "bad http://ofb.gouv.fr\n",
            "parcs\n",
            "orga\n",
            "bad http://eaurmc.fr\n",
            "oTourism\n",
            "bad http://visitvar.fr\n",
            "Services\n",
            "bad http://spinout.fr\n",
            "Hebergements\n",
            "bad http://campingartaudois.com\n",
            "bad http://parc.fr\n",
            "restauration\n",
            "bad http://lemediterranee-hyeres.fr\n",
            "locations\n",
            "mairies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarde\n",
        "fichierDeSortie = stockageSortie + '/ContenusSites/' + 'BadUrls.json'\n",
        "with open (fichierDeSortie, 'w', encoding='utf-8') as  fictemp: #on met tous les contenus dans un jspn\n",
        "  json .dump(BadUrl, fictemp)\n"
      ],
      "metadata": {
        "id": "Lj8Dj_ZKLvdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collecte des données de sites"
      ],
      "metadata": {
        "id": "HY7b-Wj-CrLT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNQngfXfRIGw"
      },
      "source": [
        "done = []  \n",
        "# pourrait être initialisé par un os.listdir() sur le répertoire de sortie\n",
        "     \n",
        "for ndc in CatSites.keys():\n",
        "  if ndc not in BadUrl.keys():\n",
        "    BadUrl[ndc] = []\n",
        "  if ndc not in done:\n",
        "    soup = dict() # changement de type de données pour conserver l'URL source\n",
        "  # récupère l'URL d'un site web et enregistre la page web\n",
        "    for url in CatSites[ndc][0]: \n",
        "      if url not in BadUrl[ndc]:\n",
        "        try:\n",
        "          webpage = myRequest(url)\n",
        "        except:\n",
        "          BadUrl[ndc].append(url)\n",
        "          continue\n",
        "      else:\n",
        "        continue\n",
        "  # récupère le contenu de la page web à l'aide de BeautifulSoup\n",
        "    #soup.append(BeautifulSoup(webpage.content, \"html.parser\"))\n",
        "      tempoSoup = BeautifulSoup(webpage.content, \"html.parser\")\n",
        "      if tempoSoup.title is not None:\n",
        "        titre = tempoSoup.title.text \n",
        "      else:\n",
        "        titre = \"\"\n",
        "      if tempoSoup.description is not None:\n",
        "        desc = tempoSoup.description.text \n",
        "      else:\n",
        "        desc = \"\"\n",
        "      texte = text_from_html(webpage.content)\n",
        "      if len(titre)>0 and len(desc)>0:\n",
        "        soup[url] = titre + '\\n' + desc + \"\\n\" + texte\n",
        "      elif len(titre)>0:\n",
        "        soup[url] = titre + \"\\n\" + texte\n",
        "      elif len(desc)>0:\n",
        "        soup[url] = desc + \"\\n\" + texte\n",
        "      else:\n",
        "        soup[url] = texte\n",
        "\n",
        "      # le contenu est dans le \"casier\" nommé par l'url\n",
        "    # nettoyage\n",
        "    for cle in soup.keys():\n",
        "    # soup [cle] = re.sub('^a-zA-Z0-9àâäèéêëîïôœùûüÿçÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ', ' ', soup [cle])\n",
        "      re.sub('^a-zA-ZàâäèéêëîïôœùûüÿçÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ', ' ', soup [cle])\n",
        "      soup[cle] = soup[cle].replace(\"\\xa0\", \" \")\n",
        "      soup[cle] = soup[cle].replace(\"\\n\", \" \")\n",
        "      soup[cle] = soup[cle].replace(\"’\", \"'\")\n",
        "      soup[cle] = soup[cle].translate('utf8')\n",
        "      dictionary = {\"\\\\\": \"\"}\n",
        "      transtable= soup[cle].maketrans(dictionary)\n",
        "      soup[cle] = soup[cle].translate(transtable)\n",
        "      soup[cle] = str(soup[cle])\n",
        "    \n",
        "      # sauvegarde sur Google Drive\n",
        "    #fichierDeSortie = stockageSortie + '/ContenusSites/' +CatSites [ndc][1] +'.pkl'\n",
        "    #with open (fichierDeSortie, 'wb') as  fictemp: #on met tous les contenus dans un pickle\n",
        "    #  pickle.dump(soup, fictemp)\n",
        "    fichierDeSortie = stockageSortie + '/ContenusSites/' +CatSites [ndc][1] +'.json'\n",
        "    with open (fichierDeSortie, 'w', encoding='utf-8') as  fictemp: #on met tous les contenus dans un pickle\n",
        "      json .dump(soup, fictemp)\n",
        "    done .append (ndc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQm5mqYgVeGj"
      },
      "source": [
        "# Commentaires et exemples de ce qui est récupéré\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BadUrl contient tous les url en erreur\n",
        "> Ceux-ci sont rangés par catégorie d'origine. "
      ],
      "metadata": {
        "id": "yZ5pC8KeCatd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odkUDVgOKdKj"
      },
      "source": [
        "import pprint as pp \n",
        "\n",
        "pp.pprint (BadUrl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Le collecteur produit un dictionnaire \n",
        "*   les clés du dictionnaire de sortie sont les url\n",
        "*   Le contenu du dictionnaire pour une clé donne le texte récupéré"
      ],
      "metadata": {
        "id": "Du67UkPfCG5l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px_PttxXTsvl"
      },
      "source": [
        "soup.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gn7V-QWTyQV"
      },
      "source": [
        "soup ['http://la-seyne.fr']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}